{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "mount_file_id": "1wcDoUPjRxIyMhJEQwGtm6laHwFJFsnS3",
   "authorship_tag": "ABX9TyNPsjT1coDcVnOrH6fMRP2T"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r3ZRxGpoah50"
   },
   "outputs": [],
   "source": [
    "!pip install llama-index llama-index-embeddings-huggingface openai"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Import necessary dependencies.\n",
    "import os\n",
    "import zipfile\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.core import (\n",
    "    Settings,\n",
    "    SimpleDirectoryReader,\n",
    "    VectorStoreIndex,\n",
    "    TreeIndex,\n",
    "    KnowledgeGraphIndex,\n",
    "    load_index_from_storage,\n",
    "    StorageContext,\n",
    "    PromptTemplate\n",
    ")\n",
    "from llama_index.core.graph_stores import SimpleGraphStore\n",
    "from llama_index.core.node_parser import SimpleNodeParser\n",
    "from llama_index.llms.openai import OpenAI as OpenAI_LlamaIndex\n",
    "from llama_index.core.prompts.prompt_type import PromptType\n",
    "import pandas as pd\n",
    "from IPython.display import Markdown, display\n",
    "from openai import OpenAI\n",
    "from enum import Enum\n",
    "# from sentence_transformers import CrossEncoder\n",
    "import numpy as np"
   ],
   "metadata": {
    "id": "gHPhXFD0az2A"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', None)"
   ],
   "metadata": {
    "id": "HNN276Xtaz6D"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Setup"
   ],
   "metadata": {
    "id": "hsKY5NWZbSJY"
   }
  },
  {
   "cell_type": "code",
   "source": "# Define OPENAI_API_KEY",
   "metadata": {
    "id": "j_GRCxdDaz-G"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "llm = OpenAI_LlamaIndex(model=\"gpt-4-turbo-preview\")\n",
    "Settings.llm = llm\n",
    "\n",
    "Settings.embed_model = HuggingFaceEmbedding(\n",
    "    model_name=\"BAAI/bge-small-en-v1.5\"\n",
    ")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AoL1nC5ua0Bp",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1712794242103,
     "user_tz": 300,
     "elapsed": 3502,
     "user": {
      "displayName": "Zeyu Yan",
      "userId": "00512041571302287004"
     }
    },
    "outputId": "a90ce5e4-1846-45e5-f36a-8cb9b79613b5"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "# Define root_path and documents_path",
   "metadata": {
    "id": "iKDjbG8oa0E5"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "if not os.path.exists(documents_path):\n",
    "    # Unzip the file\n",
    "    with zipfile.ZipFile(f'{root_path}/processed_subtitles.zip', 'r') as zip_ref:\n",
    "        zip_ref.extractall(root_path)"
   ],
   "metadata": {
    "id": "FQ6zAY3ma0Hz"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "files_in_directory = os.listdir(documents_path)\n",
    "number_of_files = len(files_in_directory)\n",
    "number_of_files"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iLdWhzbkbtED",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1712794242369,
     "user_tz": 300,
     "elapsed": 282,
     "user": {
      "displayName": "Zeyu Yan",
      "userId": "00512041571302287004"
     }
    },
    "outputId": "06161e75-0f48-4b2a-e227-fc029260fadf"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "documents = SimpleDirectoryReader(documents_path).load_data()\n",
    "len(documents)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "--14XbVGbtI6",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1712794309237,
     "user_tz": 300,
     "elapsed": 66877,
     "user": {
      "displayName": "Zeyu Yan",
      "userId": "00512041571302287004"
     }
    },
    "outputId": "47cc23b6-09d3-4b66-d2ac-1b9a48f086cd"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "%%time\n",
    "\n",
    "# Create or load tree index.\n",
    "SUMMARY_PROMPT_TMPL = (\n",
    "    \"Write a summary of the following. Try to use only the \"\n",
    "    \"information provided. \"\n",
    "    \"Try to include as many key math terms or keywords as possible.\\n\"\n",
    "    \"\\n\"\n",
    "    \"\\n\"\n",
    "    \"{context_str}\\n\"\n",
    "    \"\\n\"\n",
    "    \"\\n\"\n",
    "    'SUMMARY:\"\"\"\\n'\n",
    ")\n",
    "\n",
    "summary_template = PromptTemplate(\n",
    "    SUMMARY_PROMPT_TMPL,\n",
    "    prompt_type=PromptType.SUMMARY\n",
    ")\n",
    "\n",
    "TREE_INDEX_PERSIST_DIR = f'{root_path}/tree_index_storage'\n",
    "\n",
    "if not os.path.exists(TREE_INDEX_PERSIST_DIR):\n",
    "    print('Creating tree index...')\n",
    "    parser = SimpleNodeParser()\n",
    "    nodes = parser.get_nodes_from_documents(documents)\n",
    "    tree_index = TreeIndex(\n",
    "        nodes=nodes,\n",
    "        summary_template=summary_template,\n",
    "        llm=llm,\n",
    "        num_children=3,\n",
    "    )\n",
    "    tree_index.storage_context.persist(persist_dir=TREE_INDEX_PERSIST_DIR)\n",
    "else:\n",
    "    print('Loading tree index...')\n",
    "    tree_index_storage_context = StorageContext.from_defaults(persist_dir=TREE_INDEX_PERSIST_DIR)\n",
    "    tree_index = load_index_from_storage(tree_index_storage_context)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oyCYG_fVbtNF",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1712794310416,
     "user_tz": 300,
     "elapsed": 1758,
     "user": {
      "displayName": "Zeyu Yan",
      "userId": "00512041571302287004"
     }
    },
    "outputId": "55c65ee2-335c-43eb-c18f-e8a1aad12642"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Create retriever.\n",
    "tree_retriever = tree_index.as_retriever(child_branch_factor=3)"
   ],
   "metadata": {
    "id": "7sLVuBe_btRI"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Query"
   ],
   "metadata": {
    "id": "aWnLdh17ci4c"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "client = OpenAI(api_key=OPENAI_API_KEY)"
   ],
   "metadata": {
    "id": "ImFKD6HObtVT"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def generate_response(prompt):\n",
    "    chat_completion = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt,\n",
    "            }\n",
    "        ],\n",
    "        model=\"gpt-4-turbo\",\n",
    "    )\n",
    "    return chat_completion.choices[0].message.content"
   ],
   "metadata": {
    "id": "mY8AVjhmbtZD"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Define prompts.\n",
    "template_no_guidance = (\n",
    "    \"You are going to act as a mathematics tutor for a 13 year old student who is in grade 8 or 9 and lives in the United Sates.\\n\"\n",
    "    \"You will be encouraging and factual.\\n\"\n",
    "    \"Prefer simple, short responses.\\n\"\n",
    "    \"If the student says something inappropriate or off topic you will say you can only focus on mathematics and ask them if they have any math-related follow-up questions.\\n\"\n",
    "    \"Student: {query_str}\\n\"\n",
    "    \"You:\"\n",
    ")\n",
    "\n",
    "template_low_guidance = (\n",
    "    \"You are going to act as a mathematics tutor for a 13 year old student who is in grade 8 or 9 and lives in the United States.\\n\"\n",
    "    \"You will be encouraging and factual.\\n\"\n",
    "    \"Only if it is relevant, examples and language from the section below may be helpful to format your response:\\n\"\n",
    "    \"===\\n\"\n",
    "    \"{context_str}\\n\"\n",
    "    \"===\\n\"\n",
    "    \"Prefer simple, short responses.\\n\"\n",
    "    \"If the student says something inappropriate or off topic you will say you can only focus on mathematics and ask them if they have any math-related follow-up questions.\\n\"\n",
    "    \"Student: {query_str}\\n\"\n",
    "    \"You:\"\n",
    ")\n",
    "\n",
    "template_high_guidance = (\n",
    "    \"You are going to act as a mathematics tutor for a 13 year old student who is in grade 8 or 9 and lives in the United States.\\n\"\n",
    "    \"You will be encouraging and factual.\\n\"\n",
    "    \"Use examples and language from the section below to format your response:\\n\"\n",
    "    \"===\\n\"\n",
    "    \"{context_str}\\n\"\n",
    "    \"===\\n\"\n",
    "    \"Prefer simple, short responses.\\n\"\n",
    "    \"If the student says something inappropriate or off topic you will say you can only focus on mathematics and ask them if they have any math-related follow-up questions.\\n\"\n",
    "    \"Student: {query_str}\\n\"\n",
    "    \"You:\"\n",
    ")"
   ],
   "metadata": {
    "id": "ncX5SmeqXGqz"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "qa_template_no_guidance = PromptTemplate(template_no_guidance)\n",
    "qa_template_low_guidance = PromptTemplate(template_low_guidance)\n",
    "qa_template_high_guidance = PromptTemplate(template_high_guidance)"
   ],
   "metadata": {
    "id": "bD7Kgm_hbtfz"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class GuidanceLevel(Enum):\n",
    "    NO_GUIDANCE = \"no_guidance\"\n",
    "    LOW_GUIDANCE = \"low_guidance\"\n",
    "    HIGH_GUIDANCE = \"high_guidance\""
   ],
   "metadata": {
    "id": "So4PaIPCc0JK"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def generate_context(nodes, n=3):\n",
    "    # Determine which nodes to use based on the length of the nodes list\n",
    "    nodes_to_use = nodes[:n] if len(nodes) > n else nodes\n",
    "\n",
    "    # Concatenate the text of the selected nodes, separated by newline characters\n",
    "    context_str = \"\\n\".join(node.text for node in nodes_to_use)\n",
    "    context_str = context_str.strip()\n",
    "\n",
    "    return context_str"
   ],
   "metadata": {
    "id": "M71C66f5c0OF"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def generate_response_with_guidance_level(question, retriever):\n",
    "    nodes = retriever.retrieve(question)\n",
    "    context_str = generate_context(nodes)\n",
    "\n",
    "    for level in [GuidanceLevel.NO_GUIDANCE, GuidanceLevel.LOW_GUIDANCE, GuidanceLevel.HIGH_GUIDANCE]:\n",
    "        if level == GuidanceLevel.NO_GUIDANCE:\n",
    "            context_no_guidance = context_str\n",
    "            prompt = qa_template_no_guidance.format(query_str=question)\n",
    "            response_no_guidance = generate_response(prompt)\n",
    "\n",
    "        elif level == GuidanceLevel.LOW_GUIDANCE:\n",
    "            context_low_guidance = context_str\n",
    "            prompt = qa_template_low_guidance.format(context_str=context_str, query_str=question)\n",
    "            response_low_guidance = generate_response(prompt)\n",
    "\n",
    "        else:\n",
    "            context_high_guidance = context_str\n",
    "            prompt = qa_template_high_guidance.format(context_str=context_str, query_str=question)\n",
    "            response_high_guidance = generate_response(prompt)\n",
    "\n",
    "    return response_no_guidance, context_no_guidance, response_low_guidance, context_low_guidance, response_high_guidance, context_high_guidance"
   ],
   "metadata": {
    "id": "FdKlh77Vc0SO"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data"
   ],
   "metadata": {
    "id": "WbXjKMQZdZgJ"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Define data_path_posts\n",
    "df_posts = pd.read_csv(data_path_posts, low_memory=False)\n",
    "df_posts.head()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 556
    },
    "id": "cp4xZjt9c0WI",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1712794347022,
     "user_tz": 300,
     "elapsed": 36615,
     "user": {
      "displayName": "Zeyu Yan",
      "userId": "00512041571302287004"
     }
    },
    "outputId": "157d8b70-f891-4ea8-fd8f-fa6de0e0c296"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "df_posts.shape"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7dmqVjwZdY0P",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1712794347023,
     "user_tz": 300,
     "elapsed": 61,
     "user": {
      "displayName": "Zeyu Yan",
      "userId": "00512041571302287004"
     }
    },
    "outputId": "5df64f25-7b30-48b1-8023-102e1a509b37"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Define data_path_students\n",
    "df_students = pd.read_csv(data_path_students, low_memory=False)\n",
    "df_students.head()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 313
    },
    "id": "cFpHRMV_dY4a",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1712794406461,
     "user_tz": 300,
     "elapsed": 59470,
     "user": {
      "displayName": "Zeyu Yan",
      "userId": "00512041571302287004"
     }
    },
    "outputId": "957b563e-e01d-41f3-a787-cece1c9538ac"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "df_students.shape"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PVdQ3R9FdY8n",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1712794406462,
     "user_tz": 300,
     "elapsed": 96,
     "user": {
      "displayName": "Zeyu Yan",
      "userId": "00512041571302287004"
     }
    },
    "outputId": "14d8144e-e446-46d5-b18d-34a5f9415f38"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "df_students['is_student'] = (df_students['permissions'] & 1048576) > 0"
   ],
   "metadata": {
    "id": "OpC9dKR6dZAF"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df_students.head()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 313
    },
    "id": "iR0dtqOtdZDx",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1712794406468,
     "user_tz": 300,
     "elapsed": 41,
     "user": {
      "displayName": "Zeyu Yan",
      "userId": "00512041571302287004"
     }
    },
    "outputId": "561215ca-1167-4133-f375-c7e51a95ed92"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "df_posts_is_student = pd.merge(df_posts, df_students[['id.1', 'is_student']],\n",
    "                               left_on='useraccount_id', right_on='id.1',\n",
    "                               how='inner')\n",
    "df_posts_is_student = df_posts_is_student.drop(columns=['id.1'])\n",
    "df_posts_is_student.head()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Rn9mViPyekxM",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1712794408915,
     "user_tz": 300,
     "elapsed": 2478,
     "user": {
      "displayName": "Zeyu Yan",
      "userId": "00512041571302287004"
     }
    },
    "outputId": "314ea857-9076-4859-f23c-098ef2090ed7"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "df_posts_is_student.shape"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2XVE9J72ek1a",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1712794408915,
     "user_tz": 300,
     "elapsed": 91,
     "user": {
      "displayName": "Zeyu Yan",
      "userId": "00512041571302287004"
     }
    },
    "outputId": "a5a0b1fd-8cf4-4a5b-f913-d13fe2802fb4"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "df_parent_posts_students = df_posts_is_student[(df_posts_is_student['is_parent_post'] == 1) & (df_posts_is_student['is_student'] == True)]\n",
    "df_parent_posts_students.head()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 330
    },
    "id": "VJ1KCiCOek5L",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1712794408915,
     "user_tz": 300,
     "elapsed": 79,
     "user": {
      "displayName": "Zeyu Yan",
      "userId": "00512041571302287004"
     }
    },
    "outputId": "df2f25ca-e676-4fba-983b-a3377b1caf49"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "df_parent_posts_students.shape"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jzd_AA3Jek8n",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1712794408916,
     "user_tz": 300,
     "elapsed": 71,
     "user": {
      "displayName": "Zeyu Yan",
      "userId": "00512041571302287004"
     }
    },
    "outputId": "5b107a96-e204-4804-f902-c1f914fde95c"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Load algebra related subject_ids.\n",
    "# Define data_path_algebra_subject_ids\n",
    "df_algebra_subject_ids = pd.read_csv(data_path_algebra_subject_ids, low_memory=False)\n",
    "df_algebra_subject_ids"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "Zx97tUvfelB0",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1712794409095,
     "user_tz": 300,
     "elapsed": 240,
     "user": {
      "displayName": "Zeyu Yan",
      "userId": "00512041571302287004"
     }
    },
    "outputId": "0ae3d0d8-d86e-4d80-b19e-f2fcd859b653"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Perform an inner join between df_parent_posts_students and df_algebra_subject_ids\n",
    "joined_df = pd.merge(df_parent_posts_students, df_algebra_subject_ids[['id', 'name']],\n",
    "                     left_on='subject_id', right_on='id',\n",
    "                     how='inner',\n",
    "                     suffixes=('', '_algebra_subject'))\n",
    "\n",
    "# Optionally, remove the 'id_algebra_subject' column if it's not needed\n",
    "joined_df.drop(columns=['id_algebra_subject'], inplace=True)"
   ],
   "metadata": {
    "id": "Ib9w7A6zelGm"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "joined_df.head()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 400
    },
    "id": "6_w_dvEic0aD",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1712794409491,
     "user_tz": 300,
     "elapsed": 115,
     "user": {
      "displayName": "Zeyu Yan",
      "userId": "00512041571302287004"
     }
    },
    "outputId": "6c96b176-592e-44c8-a705-7aee2f9077d0"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "joined_df.shape"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ejq92S8Ye4BI",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1712794409491,
     "user_tz": 300,
     "elapsed": 97,
     "user": {
      "displayName": "Zeyu Yan",
      "userId": "00512041571302287004"
     }
    },
    "outputId": "205c9fd0-eebc-4912-f3b1-af8d4a7a584e"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "def find_replies_by_id(df, id):\n",
    "    \"\"\"\n",
    "    Find all rows in the DataFrame where 'reply_to_post_id', converted to int, matches the input id,\n",
    "    and return them ordered by 'ts_created' in ascending order. The row with the matching 'id' is\n",
    "    placed as the first row of the returned DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - df: The input DataFrame.\n",
    "    - id: The integer id to match in 'reply_to_post_id'.\n",
    "\n",
    "    Returns:\n",
    "    - A DataFrame containing the matching rows, ordered by 'ts_created', with the matching 'id' row first.\n",
    "    \"\"\"\n",
    "    # Find the original post row and set aside\n",
    "    original_post_df = df[df['id'] == id]\n",
    "\n",
    "    # Ensure the comparison is done correctly by converting 'reply_to_post_id' to integers where possible\n",
    "    filtered_df = df[pd.to_numeric(df['reply_to_post_id'], errors='coerce', downcast='integer').fillna(-1).astype(int) == id]\n",
    "\n",
    "    # Order by 'ts_created' in ascending order\n",
    "    ordered_replies_df = filtered_df.sort_values(by='ts_created', ascending=True)\n",
    "\n",
    "    # Concatenate the original post row at the top if it exists\n",
    "    if not original_post_df.empty:\n",
    "        result_df = pd.concat([original_post_df, ordered_replies_df], ignore_index=True)\n",
    "    else:\n",
    "        result_df = ordered_replies_df\n",
    "\n",
    "    return result_df"
   ],
   "metadata": {
    "id": "V9ldBfJLe4Fk"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def generate_teacher_answer_from_replies(result_df):\n",
    "    # Check if the parent post is not from a student\n",
    "    if not result_df.loc[result_df['is_parent_post'] == 1, 'is_student'].bool():\n",
    "        return np.nan\n",
    "\n",
    "    # Filter rows where is_student is False\n",
    "    teacher_replies_df = result_df[result_df['is_student'] == False]\n",
    "\n",
    "    # If there are no teacher replies, return None\n",
    "    if teacher_replies_df.empty:\n",
    "        return np.nan\n",
    "\n",
    "    # Concatenate the comment_text of teacher replies, separated by newlines\n",
    "    try:\n",
    "        comment_text_list = teacher_replies_df['comment_text'].tolist()\n",
    "        comment_text_list = [str(text) for text in comment_text_list]\n",
    "        concatenated_text = \"\\n\".join(comment_text_list)\n",
    "        # concatenated_text = \"\\n\".join(str(teacher_replies_df['comment_text']))\n",
    "        concatenated_text = concatenated_text.strip()\n",
    "    except:\n",
    "        concatenated_text = np.nan\n",
    "\n",
    "    return concatenated_text"
   ],
   "metadata": {
    "id": "kPmEHembe4Je"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Define data_path_sampled_5000\n",
    "df_sampled_5000 = pd.read_csv(data_path_sampled_5000, low_memory=False)\n",
    "df_sampled_5000.head()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 556
    },
    "id": "BCHemcgWe4NY",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1712794409693,
     "user_tz": 300,
     "elapsed": 271,
     "user": {
      "displayName": "Zeyu Yan",
      "userId": "00512041571302287004"
     }
    },
    "outputId": "6d62cc8c-2ccc-4845-bc05-38cde14f96ed"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "filtered_df = df_sampled_5000.reset_index(drop=True)\n",
    "filtered_df.head()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 556
    },
    "id": "E7manA00e4RN",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1712794409695,
     "user_tz": 300,
     "elapsed": 36,
     "user": {
      "displayName": "Zeyu Yan",
      "userId": "00512041571302287004"
     }
    },
    "outputId": "2cc2bef0-bf38-4050-d7a0-8b0542572607"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "filtered_df.shape"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p-g2iMsXe4U-",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1712794409701,
     "user_tz": 300,
     "elapsed": 29,
     "user": {
      "displayName": "Zeyu Yan",
      "userId": "00512041571302287004"
     }
    },
    "outputId": "3ac4a805-681f-43f6-b1e5-2dc01e49c0e1"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Main loop:\n",
    "data = []\n",
    "\n",
    "for i, row in filtered_df.iterrows():\n",
    "    # if i % 100 == 0:\n",
    "    print(f'Processed {i} rows.')\n",
    "    id_ = row['id']\n",
    "    question = row['comment_text']\n",
    "    result_df = find_replies_by_id(df_posts_is_student, id_)\n",
    "    teacher_answer = generate_teacher_answer_from_replies(result_df)\n",
    "\n",
    "    # Tree.\n",
    "    try:\n",
    "        response_tree_no_guidance, context_tree_no_guidance, response_tree_low_guidance, context_tree_low_guidance, response_tree_high_guidance, context_tree_high_guidance = generate_response_with_guidance_level(question, tree_retriever)\n",
    "    except:\n",
    "        response_tree_no_guidance = None\n",
    "        context_tree_no_guidance = None\n",
    "        response_tree_low_guidance = None\n",
    "        context_tree_low_guidance = None\n",
    "        response_tree_high_guidance = None\n",
    "        context_tree_high_guidance = None\n",
    "\n",
    "    data.append({\n",
    "        'id': id_,\n",
    "        'question': question,\n",
    "        'teacher_answer': teacher_answer,\n",
    "        'response_tree_no_guidance': response_tree_no_guidance,\n",
    "        'context_tree_no_guidance': context_tree_no_guidance,\n",
    "        'response_tree_low_guidance': response_tree_low_guidance,\n",
    "        'context_tree_low_guidance': context_tree_low_guidance,\n",
    "        'response_tree_high_guidance': response_tree_high_guidance,\n",
    "        'context_tree_high_guidance': context_tree_high_guidance,\n",
    "    })\n",
    "\n",
    "# Convert the data list to a pandas DataFrame\n",
    "final_df = pd.DataFrame(data)\n",
    "\n",
    "# Write the DataFrame to a CSV file\n",
    "# Save final_df"
   ],
   "metadata": {
    "id": "s3HUi1-0gqIH",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1712840152717,
     "user_tz": 300,
     "elapsed": 34512729,
     "user": {
      "displayName": "Zeyu Yan",
      "userId": "00512041571302287004"
     }
    },
    "outputId": "7ef6d22e-1feb-4c73-fa7b-c0ee6852ef87"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "0v3nxmL8gqMb"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "TMvd622YgqQi"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "24ml28Xggrhu"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "IL0b43mSgrlq"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "iZnjcHZdgrpa"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
